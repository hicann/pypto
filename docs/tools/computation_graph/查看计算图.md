# 查看计算图

## 功能说明

计算图描述PyPTO程序计算流程的结构，由多个表达数据的Tensor节点和表达数据操作的Operation节点组成。它通过有向无环图（DAG）的形式表示数据流动和计算逻辑。PyPTO中的计算图与GE（Graph Engine）计算图的概念有所不同，PyPTO的计算图包括Tensor Graph、Tile Graph、Block Graph、Execute Graph，表征了PyPTO程序从抽象计算描述到硬件执行的完整编译流程。本节介绍如何查看计算图及计算图上展示的关键信息。

## 前提条件

执行PyPTO程序，生成计算图文件。

1.  开启图编译阶段调试模式开关：

    ```python
    @pypto.jit(
        debug_options={"compile_debug_mode": 1}
    )
    ```

2.  重新执行PyPTO程序，例如：

    ```bash
    python3 examples/02_intermediate/operators/softmax/softmax.py
    ```

3.  执行结束后，在$\{work\_path\}/output/output\_\*/目录（\*代表时间戳）下生成不同阶段的计算图文件（.json 格式）。

    ```text
    ├── Pass_xx_xx
    │   ├── After_004_ExpandFunction_TENSOR_loop_0_Unroll1_PATH0_hiddenfunc0_8.json # pass优化后的计算图文件
    │   ├── After_004_ExpandFunction_TENSOR_loop_0_Unroll1_PATH0_hiddenfunc0_8.tifwkgr # 用户暂不需要关注
    │   ├── Before_004_ExpandFunction_TENSOR_loop_0_Unroll1_PATH0_hiddenfunc0_8.json # pass优化前的计算图文件
    │   ├── Before_004_ExpandFunction_TENSOR_loop_0_Unroll1_PATH0_hiddenfunc0_8.tifwkgr # 用户暂不需要关注
    │   └── ExpandFunctionTENSOR_loop_0_Unroll1_PATH0_hiddenfunc0_8.log
    ├── program.json # 记录function name, semantic label等静态信息
    ├── ...
    ```

下面将选取计算图各编译阶段的最后一张计算图文件，帮助用户了解各类计算图的关键信息。

-   Tensor Graph：Before\_004\_ExpandFunction\_TENSOR\_loop\_0\_Unroll1\_PATH0\_hiddenfunc0\_8.json
-   Tile Graph：Before\_027\_SubgraphToFunction\_TENSOR\_loop\_0\_Unroll1\_PATH0\_hiddenfunc0\_8.json
-   Block Graph：After\_037\_CodegenPreproc\_TENSOR\_loop\_0\_Unroll1\_PATH0\_hiddenfunc0\_8\_LEAF\_program\_id\_00\_15536366383870408930.json
-   Execute Graph：After\_037\_CodegenPreproc\_TENSOR\_loop\_0\_Unroll1\_PATH0\_hiddenfunc0\_8\_ROOT.json

## 查看Tensor Graph

1.  打开计算图文件，下面提供两种方式，用户任选其一即可：
    -   在Visual Studio Code侧边栏，单击![](../figures/zh-cn_image_0000002491082472.png)图标，打开PyPTO Toolkit，在运行结果界面打开计算图文件\(此种方式仅支持打开文件命名以After开头的图\)。
    -   在Visual Studio Code工作区，右键单击计算图文件，在弹出的菜单中选择“PyPTO Toolkit：打开文件”。

2.  打开Before\_004\_ExpandFunction\_TENSOR\_loop\_0\_Unroll1\_PATH0\_hiddenfunc0\_8.json文件，显示以下界面。

    ![](../figures/zh-cn_image_0000002533278571.png)

    通过上方标题右侧可以看到计算图类型为Tensor Graph。Tensor Graph由以下几部分组成：

    -   Incast/Outcast节点：数据源/数据结果节点，对应图中标号①，各参数解释参见[表1](#table1)。
    -   Tensor节点：数据节点，对应图中标号②，各参数解释参见[表2](#table2)。
    -   Operation节点：操作节点，对应图中标号③，各参数解释参见[表3](#table3)。

    从图中可以看到，Tensor Shape和代码定义一致，且没有经过Tile展开。

    **表 1**  Incast/Outcast节点参数说明<a id="table1"></a>

    |参数|说明|
    |--|--|
    |节点名称|计算图的Incast/Outcast节点名称，在卡片标题中展示。例如上图中的TENSOR_1。|
    |Magic ID|节点的唯一标识，对应卡片右上角的数字。例如上图中的7。|
    |rawTensor_MagicID|节点所属的逻辑内存块编号，一块rawTensor内存会分配给多个Tensor。对应卡片标题后面括号中的数字。例如上图中的8。|
    |Slot ID|节点所属Slot编号。若两节点的rawTensor_MagicID相同，且Slot ID相同，则这两个节点存在同地址关系。|
    |shape|节点的形状信息，为整数数组。|
    |rawshape|rawTensor的形状信息。|
    |offset|当前Tensor在rawTensor内存中的偏移量，为整数数组。|
    |asis|所处的内存层级，即该Tensor经过前一个Operation节点后所处的内存层级，与前一个Operation节点的to offset字段一致。取值示例如下，与PyPTO的MemoryType一致，此处不全部枚举。<br>MEM_UB： 统一缓冲区，用于临时数据存储和计算<br>MEM_L1： L1缓存，高速缓存，用于频繁访问的数据<br>MEM_L0A ： L0A缓存，用于矩阵数据的缓存<br>MEM_L0B ：L0B缓存，用于矩阵B数据的缓存<br>MEM_L0C ：L0C缓存，用于矩阵C数据的缓存<br>MEM_DEVICE_DDR ：设备DDR内存，主存储区域，容量大但访问较慢<br>MEM_UNKNOWN： 内存数据未输出|
    |tobe|目的内存层级，即该Tensor在下一个Operation中将在哪个内存层级进行操作。与下一个Operation节点的from字段一致。|
    |datatype|数据类型。|

    **表 2**  Tensor节点参数说明<a id="table2"></a>

    |参数|说明|
    |--|--|
    |节点名称|计算图的Tensor节点名称，在卡片标题中展示。例如上图中的INCAST_LOCAL_BUF0。|
    |Magic ID|节点的唯一标识，对应卡片右上角的数字。例如上图中的8。|
    |rawTensor_MagicID|节点所属的逻辑内存块编号，一块rawTensor内存会分配给多个Tensor。对应卡片标题后面括号中的数字。例如上图中的9。|
    |Subgraph ID|节点所在的子图的ID，当Tensor还没分配到具体子图时值为-1（切图前，即经过GraphPartition Pass前）。|
    |shape|Tensor节点的形状信息，为整数数组。|
    |rawshape|rawTensor的形状信息。|
    |offset|当前Tensor在rawTensor内存中的偏移量，为整数数组。|
    |asis|所处的内存层级，即该Tensor经过前一个Operation节点后所处的内存层级，与前一个Operation节点的to offset字段一致。取值示例如下，与PyPTO的MemoryType一致，此处不全部枚举。MEM_UB： 统一缓冲区，用于临时数据存储和计算MEM_L1： L1缓存，高速缓存，用于频繁访问的数据MEM_L0A ： L0A缓存，用于矩阵数据的缓存MEM_L0B ：L0B缓存，用于矩阵B数据的缓存MEM_L0C ：L0C缓存，用于矩阵C数据的缓存MEM_DEVICE_DDR ：设备DDR内存，主存储区域，容量大但访问较慢|
    |tobe|目的内存层级，即该Tensor在下一个Operation中将在哪个内存层级进行操作。与下一个Operation节点的from字段一致。|
    |datatype|数据类型。|

    **表 3**  Operation节点参数说明<a id="table3"></a>

    |参数|说明|
    |--|--|
    |节点名称|计算图的Operation节点名称，例如上图中的TILE_VIEW。|
    |Magic ID|当前Operation的Magic ID，一张图中Operation的Magic ID唯一。例如上图中的10007。|
    |Subgraph ID|当前节点所在的子图的ID，当前Operation还没分配到具体子图时值为-1（切图前，即在经过GraphPartition Pass前）。|
    |shape|被处理Tensor的形状信息，为整数数组。|
    |from|Operation的源操作数据的内存层级，即经过该操作前所处的内存层级，与前一个Tensor节点tobe字段一致。|
    |to offset|Operation的目的操作数据相对于源操作数据的内存偏移量。|


## 查看Tile Graph

打开Before\_027\_SubgraphToFunction\_TENSOR\_loop\_0\_Unroll1\_PATH0\_hiddenfunc0\_8.json文件，显示以下界面。

![](../figures/zh-cn_image_0000002533531967.png)

通过上方标题右侧可以看到计算图类型为Tile Graph。Tile Graph由以下几部分组成：

-   Incast/Outcast节点：数据源/数据结果节点，对应图中标号①，各参数解释参见[表1](#table1)。
-   Tensor节点：数据节点，对应图中标号②，各参数解释参见[表2](#table2)。
-   Operation节点：操作节点，对应图中标号③和④，两者的区别是④这类Operation与输入/输出Tensor的Shape无关，因此无Shape属性，详细参数解释参见[表3](#table3)。

从图中可以看到，相比于Tile展开前，Tile Graph中增加了很多节点，这是因为原Shape为\(-1, 32, 1, 256\)的Tensor经过Tile展开，切分成Shape为\(1, 4 ,1, 64\)的Tile。同时，为Tile分配内存层级（对应图中asis-原地址，tobe-目的地址），并将Tensor前后关联的Operation节点进行切分和处理（例如图中TILE\_COPY\_IN和TILE\_COPY\_OUT等）。

## 查看Block Graph

打开After\_037\_CodegenPreproc\_TENSOR\_loop\_0\_Unroll1\_PATH0\_hiddenfunc0\_8\_LEAF\_program\_id\_00\_15536366383870408930.json，显示以下界面。

![](../figures/zh-cn_image_0000002501792452.png)

通过上方标题右侧可以看到计算图类型为Block Graph。Block Graph由以下几部分组成：

-   Incast/Outcast节点：数据源/数据结果节点，对应图中标号①，各参数解释参见[表1](#table1)。
-   Tensor节点：对应图中标号②，各参数解释参见[表2](#table2)。
-   Operation节点：对应图中标号③和④，两者的区别是例如④这类Operation与输入/输出Tensor的Shape无关，因此无Shape属性，详细参数解释参见[表3](#table3)。

从图中可以看到，在Block Graph阶段，Tile Graph被切成若干子图，每一个子图对应一个Block Graph，因此相比Tile Graph，Block Graph的规模明显减少。

当前sample被切分成多个结构相同的子图（简称同构子图），因此Pass\_36\_CodegenPreproc目录下仅有一个文件名称包含After\_036\_CodegenPreproc\_\*\_**LEAF**\_\*关键字的json文件。

## 查看Execute Graph

打开After\_037\_CodegenPreproc\_TENSOR\_loop\_0\_Unroll1\_PATH0\_hiddenfunc0\_8\_ROOT.json文件，显示以下界面。

![](../figures/zh-cn_image_0000002501621864.png)

通过上方标题右侧可以看到计算图类型为Execute Graph。Execute Graph由以下几部分组成：

-   Incast/Outcast节点：数据源/数据结果节点，对应图中标号①，各参数解释参见[表1](#table1)。
-   调用节点：带有fx标识，表示对Block Graph进行一次调用，对应图中标号②，各参数解释参见[表4](#table4)。双击调用节点，可以查看对应的Block Graph子图信息，了解具体的执行过程。

    **表 4**  调用节点说明<a id="table4"></a>

    |参数|说明|
    |--|--|
    |调用节点名称|调用节点仅在Execute Graph中显示，节点卡片右下方带有fx标识。节点名称带有CALL前缀，作为可调度运行在AI Core上的Block Graph子图的入口节点。双击调用节点可以跳转到Block Graph子图。|
    |Subgraph ID|所在的子图的ID。|
    |InCast|输入Tensor的Magic ID列表。|
    |OutCast|输出Tensor的Magic ID列表。|


## 其他操作

在计算图页面支持拖拽查看、缩略图查看，以及节点的缩放、点击查看节点详情。

