# 编译与执行流程

当开发者完成对Tensor的定义，并通过一系列对Tensor的基本运算构建完整的计算流程后，系统会生成由Tensor和Operation交错连接的图结构，即计算图。该计算图经过PyPTO编译优化流程，完成从原始计算图到可执行图的编译过程，最终生成可在昇腾硬件环境中运行的可执行代码，以实现实际的计算任务。

## 图编译流程

[图1](#fig9712193702515)展示了完整的计算图编译过程，Tensor Graph、Tile Graph、Block Graph阶段会经历多个Pass的优化，最终通过Execute Graph阶段整合图信息，编程生成最终的硬件执行图。

具体Pass列表请参见：framework/src/passes/pass\_mgr/pass\_manager.cpp文件。

**图 1**  计算图编译流程  
![](../figures/计算图编译流程.png "计算图编译流程")

计算图编译各阶段生成的图分别为Tensor Graph、Tile Graph、Block Graph，Execute Graph，这些图是编译过程中的关键产物，表征了PyPTO程序从抽象计算描述到硬件执行的完整编译流程。

-   **Tensor Graph**：Tensor Graph由Tensor和Operation节点构成，用于描述用户定义的计算流程。该图不涉及Tile展开与内存层级等底层语义，仅作为高层计算逻辑的表达。基于Tensor Graph的优化主要集中在与硬件无关的通用图优化技术上，例如冗余节点消除、常量折叠等。
-   **Tile Graph**：Tile Graph由Tile和TileOp构成。Tensor Graph根据TileShape展开，将Tensor分解为Tile，将Operation分解为TileOp。Tile Graph依据TileOp信息以及目标硬件的内存层级，自动推导Tile的存储位置，并在必要时插入内存搬运节点，确保数据在不同内存层级之间正确传输。
-   **Block Graph**：Block Graph通过将Tile Graph切分为多个子图，使得每个子图可以调度运行在单个AI Core上。Block Graph用于硬件相关的优化，包括指令编排、片上内存分配、同步操作插入等，从而提升硬件执行效率。
-   **Execute Graph**：Execute Graph是编译流程的最终产物，整合了所有优化结果，精确描述各Block Graph之间的依赖关系，用于设备调度器的调度执行。

借助PyPTO Toolkit可视化工具，可以直观地查看计算图结构，了解计算图的节点信息，从而帮助开发者更便捷地进行算子功能调试。

## 图执行流程

[图2](#fig242151818494)展示了从资源准备、任务下发到计算运行的完整执行过程。

-   资源准备阶段：根据Execute Graph中描述的执行资源信息，向执行硬件申请如workspace内存、Stream等全局资源。
-   任务参数组装和下发阶段：PyPTO的硬件执行任务分为AI CPU任务和AI Core任务。完成这两类任务所需的参数组装和任务配置后，提交给RTS以完成任务下发。
-   任务执行阶段：通过AI CPU和AI Core之间类Client-Server架构的紧密配合，完成整个计算任务的执行。AI CPU基于Execute Graph完成子任务的解析和分发，AI Core则负责接收AI CPU分发的子任务并完成运行。

在执行前，可以启用泳道图的采集和输出，利用PyPTO Toolkit可视化工具，直观查看各个子任务在AIC/AIV上的核间并行关系及前后执行顺序，从而帮助开发者更便捷地了解整体流水线分布，并进行针对性的算子性能优化。

**图 2**  计算图执行流程  
![](../figures/计算图执行流程.png "计算图执行流程")

[图3](#fig18488927184915)展示了PyPTO任务在硬件运行时的AI CPU与AI Core的关系，以及详细的运行流程。主要过程概括为：HostMachine初始化资源\>DeviceMachine通过Stitch生成DeviceTask并调度CallTask\>CoreMachine执行CallTask\>DeviceProgram协调整个流程。

-   HostMachine：运行在Host侧，负责实际的硬件任务执行，包括资源准备、任务组装等。
-   DeviceMachine：运行在AI CPU侧，基于Execute Graph等执行态数据，负责AI Core执行子任务的分发和调度。具体流程为：Control-AICPU通过Stitch（字面意为“缝合”）将多个无依赖关系的Loop内的CallTask整合到一个DeviceTask中，以打破循环边界并最大化CallTask的并行度；Schedule-AICPU基于DeviceTask完成AI Core-CallTask的分发和管理。每个DeviceTask在3个Schedule-AICPU之间共享，各Schedule-AICPU根据所管理的AIC/AIV核的空闲状态，从DeviceTask中提取就绪的CallTask下发执行。
-   CoreMachine：运行在AI Core侧，负责接收来自AI CPU分发的CallTask并完成执行。CallTask是在 AIC/AIV 上运行的最小单元，由一系列CCE指令组成，用于在AI Core上执行具体的搬运和计算任务。
-   DeviceProgram：DeviceProgram是每个PyPTO算子在Device侧运行的核心数据，由Execute Graph中描述的信息结合硬件资源管理生成。

**图 3**  执行态运行示意图  
![](../figures/执行态运行示意图.png "执行态运行示意图")

