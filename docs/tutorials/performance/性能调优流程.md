# 性能调优流程

## 简介

在融合算子的开发过程中，算子性能优化通常难度极高。本章旨在介绍如何利用PyPTO Toolkit可视化工具，帮助开发者在无需深入了解硬件实现细节的情况下，完成高性能融合算子的编写。

## 整体流程

在完成精度调试后，开发者可以利用PyPTO Toolkit查看对应算子的泳道图，泳道图用于直观展示计算图的实际调度与执行过程，清晰呈现任务的执行顺序和耗时信息。基于此，开发者可以得到所编写算子的初版性能，亦可称之为开箱性能。

通过观察泳道图，开发者可以观察到当前算子实现的性能瓶颈点。在观察到瓶颈点后，通过调整Tiling配置和采用不同的计算图编译策略，得到新实现下的算子泳道图，进行进一步地调整，逐步提升算子性能，实现Man-In-The-Loop（人工参与的优化流程）的调优。

## 性能调优工具

### 采集泳道图数据

1.  通过给@pypto.jit装饰器的入参debug_options配置图执行阶段调试开关启动性能数据采集功能。

    ```python
    @pypto.jit(
        debug_options={"runtime_debug_mode": 1}
    )
    ```

2.  执行用例

    ```bash
    python3 examples/02_intermediate/operators/softmax/softmax.py
    ```

3.  生成泳道图json文件

    在当前工作目录的output/output\_时间戳目录下生成merged\_swimlane.json，该文件为泳道图数据文件。

### 查看泳道图数据

1.  通过PyPTO Toolkit插件查看泳道图。

    右键单击json文件，在弹出的菜单中选择“使用PyPTO Toolkit打开”，如下图所示。

    **图 1**  查看泳道图  
    ![](../figures/view_swimlane_graph.png "查看泳道图")

    图中展示了任务的执行顺序和耗时信息，帮助开发者分析性能瓶颈。

## 性能调优手段

### Tiling配置

融合算子实现通常比较复杂，在不同的配置场景下（例如不同的BatchSize，是否开MTP等），无法通过一套Tiling配置达到所有场景的高性能实现。开发者可以根据所需适配的场景，灵活调整Tiling配置，完成高性能算子的编写。

当然，Tiling配置存在甜点区，以下为一些较为常见的Tiling配置，以便开发者在开发初期就可以获得不错的开箱性能：

-   Cube计算的TileShape，例如在进行BF16/FP16的Matmul计算时，参考设置如下：

    ```python
    # BF16/FP16的矩阵乘计算建议采用如下的TileShape：
    pypto.set_cube_tile_shapes([128, 128], [128, 128], [128, 128])
    ```

-   Vector计算的TileShape，按照Tensor形状，16KB原则确定。其中16KB原则是指，对于Vector计算，一个Tile块的大小控制在16KB-64KB之间，尾轴32B对齐，这样是个较为合适的Tile切分，参考设置如下：

    ```python
    # Vector的相关计算建议采用如下的TileShape：
    pypto.set_vec_tile_shapes(64, 512)
    ```

-   归约类计算尽可能不要在归约轴上进行Tile切分。

### 调整计算图编译策略

在调整Tiling配置的基础上，PyPTO提供了多种配置项用于优化计算图。这些配置项主要围绕子图切分和子图合并两个核心过程进行调节，旨在平衡计算并行度、数据局部性、内存占用以及核间/核内负载均衡。在调优阶段，开发者可以根据具体场景需求，灵活调整编译策略，以实现性能优化。编译策略配置方式如下：

```python
pypto.set_pass_options(pg_skip_partition=False)
```

根据作用，支持配置项可以分为以下几类：

1.  切分控制：控制原始图切分的细碎程度。
    -   pg\_skip\_partition：全局开关，跳过切分则后续所有合并策略失效。
    -   pg\_lower\_bound：避免子图过碎，当子图大小小于该值时倾向于合并。
    -   pg\_upper\_bound：避免子图过大，当子图大小大于该值时禁止进一步合并。

2.  合并策略：将小的子图合并成更大更高效执行的单元。
    -   通用并行度控制：pg\_parallel\_lower\_bound和mg\_vec\_parallel\_lb，控制相同结构的子图和AIV子图的最小并行度，低于此值不合并。
    -   手动控制合图：sg\_set\_scope，将operation赋予特定的scopeId，若相邻的operation具有相同的非-1的scopeId，则会被强制合并在一个子图之中，并且这个子图不会与其他子图合并。
    -   AIV子图合并（NBufferMerge Pass）：vec\_nbuffer\_mode和vec\_nbuffer\_setting：用于控制相同结构向量子图的合并策略和数量。
    -   AIC子图合并（L1ReuseMerge Pass）：
        -   cube\_l1\_reuse\_mode和cube\_l1\_reuse\_setting：合并有重复GM-\>L1数据搬运的Cube子图，减少数据搬运开销。
        -   cube\_nbuffer\_mode和cube\_nbuffer\_setting：合并同结构的Cube子图，增大核内流水调度机会。
        -   mg\_copyin\_upper\_bound：控制合并后子图的大小上界，防止因合并导致单个子图数据搬运量过大。

开发者在使用时建议按照以下思路开展：

1.  首选默认配置：从默认配置开始，如果性能不达标且系统资源充足，再向“性能优先”方向调整。
2.  使用日志和泳道图分析方法：识别出性能关键路径上的子图及其hash order。
3.  优先调节cube\_l1\_reuse\_mode：如果发现存在大量数据可复用的Cube子图且合并不足，先尝试调整全局l1\_reuse值。
4.  使用\*\_setting配置项进行精细控制：
    1.  对合并仍不足的关键子图，使用cube\_l1\_reuse\_setting或cube\_nbuffer\_setting加大合并。
    2.  对合并后过大或触达阈值的子图，使用\*\_setting适当降低其合并力度。
    3.  对无数据复用但同构的海量子图，使用cube\_nbuffer\_setting进行有效合并。

5.  监控内存：增加合并力度时，务必关注内存消耗（特别是L1），避免触发错误，mg\_copyin\_upper\_bound是防止合并过度的安全阀。

### 调整计算图调度策略

除了调整Tiling配置和计算图编译策略，PyPTO提供了不同的调度策略，开发者在使用时尝试不同的调度策略以得到最优的性能。

-   0：默认调度
-   1：L2亲和调度，选择最新依赖ready的子图优先下发，达到复用L2cache的效果
-   2：公平调度，aicpu上多线程调度管理多个aicore的时候，下发子图会尽量控制在多线程间的公平性

调度策略配置方式如下：

```python
pypto.set_runtime_options(device_sched_mode=0)
```