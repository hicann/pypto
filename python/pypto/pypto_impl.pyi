#!/usr/bin/env python3
# coding: utf-8
# Copyright (c) 2025 Huawei Technologies Co., Ltd.
# This program is free software, you can redistribute it and/or modify it under the terms and conditions of
# CANN Open Software License Agreement Version 2.0 (the "License").
# Please refer to the License for details. You may not use this file except in compliance with the License.
# THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
# INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
# See LICENSE in the root of the software repository for the full text of the License.
# -----------------------------------------------------------------------------------------------------------
import enum
from typing import Iterator, overload, Union, List, Dict, Tuple, Optional


class DataType(enum.Enum):
    DT_INT4 = ...
    DT_INT8 = ...
    DT_INT16 = ...
    DT_INT32 = ...
    DT_INT64 = ...
    DT_FP8 = ...
    DT_FP16 = ...
    DT_FP32 = ...
    DT_BF16 = ...
    DT_HF4 = ...
    DT_HF8 = ...
    DT_UINT8 = ...
    DT_UINT16 = ...
    DT_UINT32 = ...
    DT_UINT64 = ...
    DT_BOOL = ...
    DT_DOUBLE = ...
    DT_BOTTOM = ...


class ScatterMode(enum.Enum):
    NONE = ...      # 仅做数据搬运
    ADD = ...       # 加法模式
    MULTIPLY = ...  # 乘法模式


class NodeType(enum.Enum):
    LOCAL = ...
    INCAST = ...
    OUTCAST = ...


class TileOpFormat(enum.Enum):
    TILEOP_ND = ...
    TILEOP_NZ = ...


class CachePolicy(enum.Enum):
    NONE_CACHEABLE = ...


class ReduceMode(enum.Enum):
    ATOMIC_ADD = ...


class FunctionType(enum.Enum):
    STATIC = ...
    DYNAMIC = ...
    DYNAMIC_LOOP = ...


class GraphType:
    TENSOR_GRAPH = ...


class CastMode(enum.Enum):
    CAST_NONE = ...
    CAST_RINT = ...
    CAST_ROUND = ...
    CAST_FLOOR = ...
    CAST_CEIL = ...
    CAST_TRUNC = ...
    CAST_ODD = ...


class LogBaseType(enum.Enum):
    LOG_E = ...
    LOG_2 = ...
    LOG_10 = ...


class OpType(enum.Enum):
    EQ = ...
    NE = ...
    LT = ...
    LE = ...
    GT = ...
    GE = ...


class OutType(enum.Enum):
    BOOL = ...
    BIT = ...


class ReLuType(enum.Enum):
    NO_RELU = ...
    RELU = ...


class Element:

    def __init__(self, dtype: DataType, data: Union[int, float]): ...

    def _get_signed_data(self) -> int: ...

    def _get_float_data(self) -> float: ...

    def _get_data_type(self) -> DataType: ...

    def _is_float(self) -> bool: ...


class SymbolicScalar:

    @overload
    def __init__(self): ...

    @overload
    def __init__(self, name: str): ...

    @overload
    def __init__(self, value: int): ...

    @overload
    def __init__(self, name: str, val: int): ...

    def IsImmediate(self) -> bool: ...

    def IsSymbol(self) -> bool: ...

    def IsExpression(self) -> bool: ...

    def ConcreteValid(self) -> bool: ...

    def Concrete(self) -> int: ...

    def AsIntermediateVariable(self) -> None: ...

    def Dump(self) -> str: ...

    def Eq(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Ne(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Lt(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Le(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Gt(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Ge(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def RAdd(self, other: int) -> SymbolicScalar: ...

    def RSub(self, other: int) -> SymbolicScalar: ...

    def RMul(self, other: int) -> SymbolicScalar: ...

    def RDiv(self, other: int) -> SymbolicScalar: ...

    def RMod(self, other: int) -> SymbolicScalar: ...

    def Add(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Sub(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Mul(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Div(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Mod(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Pos(self) -> SymbolicScalar: ...

    def Neg(self) -> SymbolicScalar: ...

    def Not(self) -> SymbolicScalar: ...


class Tensor:

    @overload
    def __init__(self): ...

    @overload
    def __init__(self, dtype: DataType, shape: List[int],
                 name: str = "", format: TileOpFormat = TileOpFormat.TILEOP_ND): ...

    @overload
    def __init__(self, dtype: DataType, shape: List[SymbolicScalar],
                 name: str = "", format: TileOpFormat = TileOpFormat.TILEOP_ND): ...

    def GetDataType(self) -> DataType: ...

    def GetShape(self) -> List[int]: ...

    def GetValidShape(self) -> List[SymbolicScalar]: ...

    def Move(self, other: Tensor) -> Tensor: ...

    def SetCachePolicy(self, policy: CachePolicy, value: bool): ...

    def GetCachePolicy(self, policy: CachePolicy) -> bool: ...

    def SetName(self, name: str): ...

    def GetName(self) -> str: ...

    def Id(self) -> int: ...

    def Dim(self) -> int: ...

    def Format(self) -> TileOpFormat: ...


def GetInputShape(a: Tensor, axis: int) -> SymbolicScalar: ...


def GetTensorData(
        a: Tensor, offset: List[SymbolicScalar]) -> SymbolicScalar: ...


def SetTensorData(value: SymbolicScalar,
                  offset: List[SymbolicScalar], dst: Tensor): ...


def SetLocation(fname: str, lineno: int, backtrace: str) -> None: ...


def ClearLocation() -> None: ...


class DeviceTensorData:

    def __init__(self, dtype: DataType, addr: int, shape: List[int]): ...

    def GetDataType(self) -> DataType: ...

    def GetDataPtr(self) -> int: ...

    def GetShape(self) -> List[int]: ...


class RecordIfBranch:

    def __init__(self, cond: SymbolicScalar,
                 file: str = "", line: int = 0): ...

    def __bool__(self) -> bool: ...


class LoopRange:

    def __init__(self, start: SymbolicScalar, stop: SymbolicScalar,
                 step: Union[SymbolicScalar, int]): ...

    def Dump(self) -> str: ...

    def Begin(self) -> SymbolicScalar: ...

    def End(self) -> SymbolicScalar: ...

    def Step(self) -> SymbolicScalar: ...


def IsLoopBegin(symbol: SymbolicScalar, begin: SymbolicScalar) -> SymbolicScalar: ...


def IsLoopEnd(symbol: SymbolicScalar, end: SymbolicScalar) -> SymbolicScalar: ...


class RecordFunc:

    @overload
    def __init__(self, name: str): ...

    @overload
    def __init__(self, name: str, args: List[Tensor]): ...

    @overload
    def __init__(self, name: str, inputs: List[Tensor] = [], outputs: List[Tensor] = [],
                 inplaces: List[tuple[Tensor, Tensor]] = []): ...

    def EndFunction(self): ...


class RecordLoopFunc:

    def __init__(self, name: str, func_type: FunctionType, iter_name: str, loop_range: LoopRange,
                 unroll_List: set[int] = set(), submit_before_loop: bool = False): ...

    def __iter__(self) -> Iterator[SymbolicScalar]: ...


def BeginFunction(name: str, graph_type: GraphType,
                  func_type: FunctionType, *args): ...


def EndFunction(name: str, generate_call: bool = True): ...


def GetWorkSpaceSize(handle: int, inputs: List[DeviceTensorData], outputs: List[DeviceTensorData]) -> int: ...


def SetVecTile(*shapes: int): ...


def GetVecTile() -> List[int]: ...


def SetCubeTile(m: List[int], k: List[int],
                n: List[int], enable_multi_data_load: bool = False, enable_split_k: bool = False): ...


def GetCubeTile() -> Tuple[List[int], List[int], List[int], bool, bool]: ...


def SetMatrixSize(size: List[int]): ...


def SetBuildStatic(static: bool): ...


def SetSemanticLabel(label: str, filename: str, lineno: int): ...


@overload
def SetOption(key: str, value: bool): ...


@overload
def SetOption(key: str, value: str): ...


@overload
def SetOption(key: str, value: int): ...


@overload
def SetOption(key: str, value: List[int]): ...


@overload
def SetOption(key: str, value: Dict[int, int]): ...


def GetOptions() -> Dict[str, Union[bool, str, int, List[int], Dict[int, int]]]: ...


def SetPrintOptions(edge_items: int, precision: int, threshold: int, linewidth: int): ...


def BytesOf(t: DataType) -> int: ...


def ResetOptions(): ...


def Reset(): ...


def Dump() -> str: ...


# runtime
def DeviceInit(): ...


def DeviceFini(): ...



def CopyToHost(devTensor: DeviceTensorData, hostTensor: DeviceTensorData): ...



def SetVerifyData(inputs: List[DeviceTensorData],
                  outputs: List[DeviceTensorData],
                  goldens: List[DeviceTensorData]): ...


def OperatorDeviceRunOnceDataFromDevice(operator_id: int,
                                        a: List[DeviceTensorData],
                                        dst: List[DeviceTensorData],
                                        stream_id: int,
                                        workspace_ptr: int): ...


def DeviceRunOnceDataFromHost(a: List[DeviceTensorData],
                              dst: List[DeviceTensorData]): ...


def OperatorBegin() -> int: ...


def OperatorEnd(operator_id: int): ...


def OperatorDeviceSynchronize(stream_id: int): ...


def CostModelRunOnceDataFromHost(a: List[DeviceTensorData],
                              dst: List[DeviceTensorData]): ...

# operations


def Add(a: Tensor, b: Union[Tensor, Element]) -> Tensor: ...


def Sub(a: Tensor, b: Union[Tensor, Element]) -> Tensor: ...


def Mul(a: Tensor, b: Union[Tensor, Element]) -> Tensor: ...


def Div(a: Tensor, b: Union[Tensor, Element]) -> Tensor: ...


@overload
def View(a: Tensor, shapes: List[int],
         offsets: List[Union[int, SymbolicScalar]]) -> Tensor: ...


@overload
def View(a: Tensor, shapes: List[int], valid_shape: Optional[List[Union[int, SymbolicScalar]]],
         offsets: List[Union[int, SymbolicScalar]]) -> Tensor: ...


@overload
def View(a: Tensor, dtype: DataType) -> Tensor: ...


def Exp(a: Tensor) -> Tensor: ...


def Transpose(a: Tensor, axis: List[int]) -> Tensor: ...


def Abs(a: Tensor) -> Tensor: ...


def Reciprocal(a: Tensor) -> Tensor: ...


def Rsqrt(a: Tensor) -> Tensor: ...


def Sqrt(a: Tensor) -> Tensor: ...


def Neg(a: Tensor) -> Tensor: ...


def Log(a: Tensor, base: LogBaseType) -> Tensor: ...


def Cast(a: Tensor, dtype: DataType, mode: CastMode) -> Tensor: ...

def index_select(src: Tensor,  dim: int,  indices: Tensor) -> Tensor: ...

@overload
def Scatter(self: Tensor, indices: Tensor, src: Element, axis: int, 
            reduce: ScatterMode = ScatterMode.NONE) -> Tensor: ...
@overload
def Scatter(self: Tensor, indices: Tensor, src: Tensor, axis: int, 
            reduce: ScatterMode = ScatterMode.NONE) -> Tensor: ...


def Full(elem: Union[int, float, SymbolicScalar, Element], shape: List[int],
         valid_shape: Optional[List[Union[int, SymbolicScalar]]] = None) -> Tensor: ...


@overload
def Reshape(a: Tensor, shape: List[int], valid_shape: Optional[List[Union[int, SymbolicScalar]]] = None,
            inplace: bool = False) -> Tensor: ...


@overload
def Reshape(a: Tensor, shape: List[SymbolicScalar], inplace: bool) -> Tensor: ...


@overload
def Maximum(a: Tensor, b: Tensor) -> Tensor: ...


@overload
def Maximum(a: Tensor, b: Element) -> Tensor: ...


@overload
def Minimum(a: Tensor, b: Tensor) -> Tensor: ...


@overload
def Minimum(a: Tensor, b: Element) -> Tensor: ...


def Unsqueeze(a: Tensor, axis: int) -> Tensor: ...


def Expand(a: Tensor, shape: List[int], valid_shape: Union[List[Union[int, SymbolicScalar]]] = [
]) -> Tensor: ...


def Where(a: Tensor, b: Union[Tensor, Element], c: Union[Tensor, Element]) -> Tensor: ...


def Assign(a: Tensor) -> Tensor: ...


class MatmulExtendParam:
    @overload
    def __init__(self): ...

    @overload
    def __init__(self, bias_tensor: Tensor, scale_tensor: Tensor,
                 scale: int = 0, relu_type: ReLuType = ReLuType.NoReLu): ...


@overload
def Matmul(dtype: DataType, a: Tensor, b: Tensor, a_trans: bool = False,
           b_trans: bool = False, c_matrix_nz: bool = False) -> Tensor: ...


@overload
def Matmul(dtype: DataType, a: Tensor, b: Tensor, a_trans: bool = False,
           b_trans: bool = False, c_matrix_nz: bool = False, extend_params: MatmulExtendParam = None) -> Tensor: ...


def Batch_matmul(dtype: DataType, a: Tensor, b: Tensor, a_trans: bool = False,
                 b_trans: bool = False, c_matrix_nz: bool = False) -> Tensor: ...


@overload
def Assemble(a: List[Tuple[Tensor, List[SymbolicScalar]]], dst: Tensor,
             parallel: bool = False) -> None: ...


@overload
def Assemble(a: Tensor, offset: List[SymbolicScalar], dst: Tensor) -> None: ...


# pass config
class PassConfigKey(enum.Enum):
    KEY_DUMP_GRAPH = ...


class PassConfigs:
    printGraph = ...
    dumpGraph = ...
    dumpPassTimeCost = ...
    preCheck = ...
    postCheck = ...
    disablePass = ...
    healthCheck = ...


def GetPassDefaultConfig(key: PassConfigKey, default_value: bool) -> bool: ...


def SetPassDefaultConfig(key: str, value: bool): ...


def GetPassConfig(strategy: str, identifier: str, key: PassConfigKey, default_value: bool) -> bool: ...


def SetPassConfig(strategy: str, identifier: str, key: PassConfigKey, value: bool): ...


def GetPassConfigs(strategy: str, identifier: str) -> PassConfigs: ...


def GetOptionsTree() -> str: ...


def LogTopFolder() -> str: ...


def ResetLog(path: str): ...
