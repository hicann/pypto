#!/usr/bin/env python3
# coding: utf-8
# Copyright (c) 2025 CANN community contributors.
# This program is free software, you can redistribute it and/or modify it under the terms and conditions of
# CANN Open Software License Agreement Version 2.0 (the "License").
# Please refer to the License for details. You may not use this file except in compliance with the License.
# THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
# INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
# See LICENSE in the root of the software repository for the full text of the License.
# -----------------------------------------------------------------------------------------------------------

"""PTO Script Parser."""
from collections.abc import Iterator
import inspect
import functools
import re
from typing import Any, Optional, Union, Callable

import pypto
from pypto.symbolic_scalar import SymbolicScalar
from . import doc
from .context import Context
from .diagnostics import DiagnosticLevel, Diagnostics, Source
from .error import ParserError, RenderedParserError
from .evaluator import ExprEvaluator
from .liveness import LivenessAnalyzer

ParamSpec = tuple[str, bool, Any]


class NestedFunctionMarker:
    """Marker used to identify functions intended for nested inline execution."""

    def __init__(self) -> None:
        self._original_func: Optional[Callable] = None
        self._func_name: str = ""


DEFAULT_VISIT = {
    "Interactive",
    "Module",
    "Expression",
    "Pass",
}


def _catch_parser_errors(func):
    """Decorator to normalize parser error handling for public APIs."""

    @functools.wraps(func)
    def wrapper(self, *args, **kwargs):
        try:
            return func(self, *args, **kwargs)
        except RenderedParserError:
            # Flush any pending messages (like context info) in the current diagnostics
            if hasattr(self, "diag"):
                self.diag._render()
            # Already rendered; just re-raise.
            raise
        except ParserError as err:
            # User-triggered parser error with location info.
            self.diag.error(err.node, str(err))
        except Exception as err:  # pylint: disable=broad-except
            # Unexpected native error, surface as bug; try to find a node.
            node = kwargs.get("node")
            if node is None:
                for arg in args:
                    if isinstance(arg, doc.AST):
                        node = arg
                        break
            self.diag.bug(node, str(err))

    return wrapper


class Parser(doc.NodeVisitor):
    """Main parser for PTO Script that converts Python AST to PTO IR.

    The Parser class implements the visitor pattern to traverse the doc AST and
    generate PTO intermediate representation. It manages variable scoping through
    the Context system, evaluates expressions using ExprEvaluator, and reports
    errors through the Diagnostics system.

    Key Features
    ------------
    - Lazy parsing: AST preparation is separated from IR generation
    - Dynamic dimension binding: Symbolic dimensions resolved at runtime
    - Automatic memory management: Variables deleted based on liveness analysis
    - Nested function inlining: Functions marked with @function are inlined
    - Rich error reporting: Source-aware error messages with context

    Parsing Workflow
    ----------------
    1. parse(): Prepare AST and run liveness analysis
    2. bind_dynamic_dims_from_inputs(): Optionally bind symbolic dimensions
    3. execute(): Traverse AST and generate PTO IR
    4. Result: pypto.Function ready for compilation and execution

    Attributes
    ----------
    diag : Diagnostics
        Diagnostics instance for error reporting with source locations.
    context : Context
        Context instance managing variable scopes and lifetime.
    delete_after : dict[int, set[str]]
        Mapping from statement IDs to variables to delete after that statement.
        Generated by liveness analysis to enable automatic memory management.
    _parsed_node : Optional[doc.AST]
        The prepared AST node, stored after parse() for lazy execution.
    _parsed_extra_vars : dict[str, Any]
        Extra variables (globals, nonlocals) captured from the original function.
    _result : Optional[Any]
        The result of parsing, typically a pypto.Function object.
    _signature_cache : Optional[tuple[list[pypto.Tensor], list[pypto.Tensor]]]
        Cached function signature (inputs, outputs) to avoid re-parsing.
    _lowered_signature_cache: Optional[tuple[list[pypto.Tensor], list[pypto.Tensor]]]
        Cached function signature (inputs, outputs) with symbolic dimensions lowered to concrete values.
    _bound_dim_values : Optional[dict[str, int]]
        Mapping from symbolic dimension names to their concrete values.

    Examples
    --------
    >>> source = Source(my_function)
    >>> parser = Parser(source, captured_vars)
    >>> parser.parse()
    >>> parser.bind_dynamic_dims_from_inputs([[1024, 1024]])
    >>> pto_func = parser.execute()
    """

    diag: Diagnostics
    context: Context
    delete_after: dict[int, set[str]]
    _parsed_node: Optional[doc.AST]
    _parsed_extra_vars: dict[str, Any]
    _result: Optional[Any]
    _signature_cache: Optional[tuple[list[pypto.Tensor], list[pypto.Tensor]]]
    _lowered_signature_cache: Optional[tuple[list[pypto.Tensor], list[pypto.Tensor]]]

    # ==========================================================================================
    # Public API
    # ==========================================================================================

    def __init__(
        self, source: Source, extra_vars: Optional[dict[str, Any]] = None
    ) -> None:
        self.diag = Diagnostics(source)
        self.context = Context()
        self.delete_after = {}
        self._parsed_node = None
        self._parsed_extra_vars = extra_vars or {}
        self._result = None
        self._signature_cache = None
        self._lowered_signature_cache = None
        self._bound_dim_values: Optional[dict[str, int]] = None

    @_catch_parser_errors
    def parse(self) -> "Parser":
        """The main parse method for parser (lazy mode).

        Prepares the AST but defers actual parsing until execute() is called.

        Returns
        -------
        res : Parser
            Returns self for chaining.
        """
        node = self.diag.source.as_ast()
        analyzer = LivenessAnalyzer()
        exempt_vars = set(self._parsed_extra_vars.keys())
        self.delete_after = analyzer.analyze(node, exempt_vars)

        # Store for later execution (lazy mode)
        self._parsed_node = node
        return self

    @_catch_parser_errors
    def match_input_shapes(
        self,
        input_shapes: list[list[int]],
        input_tensor_defs: Optional[list[pypto.Tensor]] = None,
    ) -> dict[str, int]:
        """Match input tensors to symbolic dimensions.

        Creates a mapping from SymbolicScalar objects (found in tensor shapes or
        as symbolic parameters) to their concrete values based on actual input data.

        Parameters
        ----------
        input_shapes : list[list[int]]
            List of input shapes.

        input_tensor_defs : Optional[list[pypto.Tensor]]
            List of input tensor definitions.

        Returns
        -------
        dict[str, int]
            Mapping from SymbolicScalar objects to their concrete values.
        """
        dim_value_map = {}

        # Get the signature to know which inputs have symbolic dimensions
        if input_tensor_defs is None:
            input_tensor_defs, _ = self.get_signature()

        def _assign_dim_value(dim: pypto.SymbolicScalar, actual_value: int) -> None:
            if dim_value_map.get(str(dim), actual_value) != actual_value:
                raise ValueError(
                    f"Symbolic scalar {dim} has multiple concrete values: {dim_value_map[dim]} and {actual_value}"
                )
            dim_value_map[str(dim)] = actual_value

        # Iterate through both the actual inputs and their definitions
        for actual_input_shape, tensor_def in zip(input_shapes, input_tensor_defs):
            if isinstance(actual_input_shape, list):
                # For Tensor inputs, map each symbolic dimension to its concrete shape value
                for axis, dim in enumerate(tensor_def.shape):
                    if isinstance(dim, pypto.SymbolicScalar):
                        # Extract the actual shape value from the input tensor
                        actual_value = actual_input_shape[axis]
                        if isinstance(actual_value, int):
                            _assign_dim_value(dim, actual_value)
            else:
                raise TypeError(
                    f"Invalid input shape type: {type(actual_input_shape)}, expected list"
                )

        return dim_value_map

    @_catch_parser_errors
    def bind_dynamic_dims_from_inputs(self, inputs: list[list[int]]) -> None:
        """Bind symbolic dimensions to concrete values using sample inputs.

        Parameters
        ----------
        inputs : list[list[int]]
            Concrete sample inputs whose shapes/values are used to resolve
            dynamic (symbolic) dimensions.

        """

        self._bound_dim_values = self.match_input_shapes(inputs)

    @_catch_parser_errors
    def get_signature(
        self,
        lower_symbolic_dims: bool = False,
    ) -> tuple[list[pypto.Tensor], list[pypto.Tensor]]:
        """Extract function signature (inputs and outputs) without full parsing.

        Returns
        -------
        res : tuple[list[pypto.Tensor], list[pypto.Tensor]]
            A tuple of (input_tensors, output_tensors).

        Raises
        ------
        RuntimeError
            If parse() was not called before get_signature().
        """

        if self._signature_cache is not None and not lower_symbolic_dims:
            return self._signature_cache

        elif self._lowered_signature_cache is not None and lower_symbolic_dims:
            return self._lowered_signature_cache

        node = self.diag.source.as_ast()

        # Find the function definition node
        if isinstance(node, doc.Module):
            for item in node.body:
                if isinstance(item, doc.FunctionDef):
                    function_node = item
                    break
            else:
                raise RuntimeError("No function definition found in parsed AST")
        else:
            raise RuntimeError("Expected Module AST node")

        # Temporarily set up context to parse signature
        with self.context.with_frame():
            for k, v in self._parsed_extra_vars.items():
                self.context.add(k, v)
            # If sample inputs were provided, use them to concretize symbolic dims.
            self._apply_bound_dim_values_to_context_frame()

            # Get input arguments (only tensors allowed)
            tensor_input_args = self._visit_arguments(function_node.args)

            # Get and validate output arguments
            output_expr = self._visit_expr(function_node.returns)
            output_tensors = self._normalize_output_annotation(
                output_expr, function_node.returns
            )

            self._signature_cache = (
                tensor_input_args,
                output_tensors,
            )

            lowered_input_tensors, lowered_output_tensors = [], []
            for input_tensor in tensor_input_args:
                shapes = [
                    -1 if isinstance(dim, pypto.SymbolicScalar) else dim
                    for dim in input_tensor.shape
                ]
                lowered_input_tensors.append(
                    pypto.Tensor(
                        shapes,
                        input_tensor.dtype,
                        input_tensor.name,
                        input_tensor.format,
                        input_tensor.data_ptr,
                        input_tensor.device,
                        input_tensor.ori_shape,
                    )
                )
            for output_tensor in output_tensors:
                shapes = [
                    -1 if isinstance(dim, pypto.SymbolicScalar) else dim
                    for dim in output_tensor.shape
                ]
                lowered_output_tensors.append(
                    pypto.Tensor(
                        shapes,
                        output_tensor.dtype,
                        output_tensor.name,
                        output_tensor.format,
                        output_tensor.data_ptr,
                        output_tensor.device,
                        output_tensor.ori_shape,
                    )
                )

            self._lowered_signature_cache = (
                lowered_input_tensors,
                lowered_output_tensors,
            )
            return (
                self._signature_cache
                if not lower_symbolic_dims
                else self._lowered_signature_cache
            )

    @_catch_parser_errors
    def execute(self) -> Any:
        """Execute the deferred parsing.

        Returns
        -------
        res : Any
            The doc AST node visiting result.

        Raises
        ------
        RuntimeError
            If parse() was not called before execute().
        """
        if self._parsed_node is None:
            raise RuntimeError("parse() must be called before execute()")

        # Return cached result if already executed
        if self._result is not None:
            return self._result

        # Execute the deferred parsing
        with self.context.with_frame():
            for k, v in self._parsed_extra_vars.items():
                self.context.add(k, v)
            # Apply any concrete bindings for symbolic dimensions
            self._apply_bound_dim_values_to_context_frame()
            self._result = self.visit(self._parsed_node)
        return self._result

    def report(self, node: doc.AST, msg: str, level: DiagnosticLevel) -> None:
        """Report a diagnostic."""
        self.diag.emit(node, msg, level)

    def visit(self, node: doc.AST) -> Any:
        """The general visiting method.

        Parameters
        ----------
        node : doc.AST
            The doc AST node.

        Returns
        -------
        res : Any
            The visiting result.
        """
        if isinstance(node, (list, tuple)):
            result = None
            for item in node:
                res = self.visit(item)
                if res is not None:
                    result = res
            return result
        if not isinstance(node, doc.AST):
            raise ParserError(
                node,
                TypeError(f"Expected doc.AST, got {type(node)}."),
            )
        name = node.__class__.__name__.split(".")[-1]

        if name in DEFAULT_VISIT:
            func = self._generic_visit
        else:
            # Convert CamelCase to snake_case for function names
            snake_case_name = re.sub(r"(?<!^)(?=[A-Z])", "_", name).lower()
            func = getattr(self, f"_visit_{snake_case_name}", None)
        if func is None:
            raise ParserError(
                node,
                f"{name} is not supported by the PTO parser yet. "
                f"Please check the documentation for supported Python features.",
            )
        return func(node)

    # ==========================================================================================
    # Private APIs (implementation details)
    # ==========================================================================================
    def _get_function_def_from_func(self, func: Any) -> Optional[doc.FunctionDef]:
        """Get FunctionDef AST node from a function object.

        Parameters
        ----------
        func : Any
            The function object (can be a callable or NestedFunctionMarker).

        Returns
        -------
        Optional[doc.FunctionDef]
            The FunctionDef AST node if found, None otherwise.
        """
        # If it's a NestedFunctionMarker, get the original function
        # Check for _original_func attribute to identify NestedFunctionMarker instances
        if hasattr(func, "_original_func"):
            func = func._original_func

        # Get the function source code
        try:
            source = Source(func)
            ast_node = source.as_ast()

            # Find the FunctionDef node in the AST
            if isinstance(ast_node, doc.Module):
                for stmt in ast_node.body:
                    if isinstance(stmt, doc.FunctionDef):
                        # Check if this is the function we're looking for
                        if stmt.name == func.__name__:
                            return stmt
            elif isinstance(ast_node, doc.FunctionDef):
                if ast_node.name == func.__name__:
                    return ast_node
        except Exception:  # pylint: disable=broad-except
            # If we can't get the AST, return None
            return None

        return None

    def _collect_function_environment(self, func: Any) -> dict[str, Any]:
        """Extract globals and nonlocals referenced by the function."""
        env: dict[str, Any] = {}
        if func is None:
            return env
        try:
            closure_vars = inspect.getclosurevars(func)
        except Exception:  # pylint: disable=broad-except
            return env
        env.update(closure_vars.globals)
        env.update(closure_vars.nonlocals)
        return env

    def _is_nested_function(self, decorator_list: list[doc.expr]) -> bool:
        """Check if a function is marked for nested calling by examining its decorators.

        Parameters
        ----------
        decorator_list : list[doc.expr]
            List of decorator expressions from the function definition.

        Returns
        -------
        bool
            True if the function is marked for nested calling, False otherwise.
        """
        for decorator in decorator_list:
            # Check if decorator is pto.frontend.function or evaluates to NestedFunctionMarker
            try:
                # Try to evaluate the decorator expression
                decorator_value = self._visit_expr(decorator)
                # Check for _original_func attribute to identify NestedFunctionMarker instances
                if hasattr(decorator_value, "_original_func"):
                    return True
            except Exception:  # pylint: disable=broad-except
                # If evaluation fails, try to check if it's a direct reference to pto.frontend.function
                # Check if it's an Attribute node like pto.frontend.function
                if isinstance(decorator, doc.Attribute):
                    # Check if it's pto.frontend.function
                    attr_chain = []
                    current = decorator
                    while isinstance(current, doc.Attribute):
                        attr_chain.insert(0, current.attr)
                        if isinstance(current.value, doc.Name):
                            attr_chain.insert(0, current.value.id)
                            break
                        elif isinstance(current.value, doc.Attribute):
                            current = current.value
                        else:
                            break
                    # Check if the chain matches pto.frontend.function
                    if (
                        len(attr_chain) >= 3
                        and attr_chain[0] == "pto"
                        and attr_chain[1] == "frontend"
                        and attr_chain[2] == "function"
                    ):
                        return True
                # Also check if it's a simple Name node that refers to function
                elif isinstance(decorator, doc.Name):
                    # Check if the name refers to pto.frontend.function in the context
                    var_values = self.context.get()
                    if decorator.id in var_values:
                        value = var_values[decorator.id]
                        # Check for _original_func attribute to identify NestedFunctionMarker instances
                        if hasattr(value, "_original_func"):
                            return True
        return False

    def _eval_expr(
        self,
        node: Union[doc.Expression, doc.expr],
        extra_vars: Optional[dict[str, Any]] = None,
    ) -> Any:
        """Evaluate an expression node using the current context.

        This method evaluates expressions during parsing, handling both regular
        expressions and special cases like nested function calls. It merges the
        current context with any extra variables provided.

        Parameters
        ----------
        node : Union[doc.Expression, doc.expr]
            The expression node to evaluate.
        extra_vars : Optional[dict[str, Any]], optional
            Additional variables to make available during evaluation.

        Returns
        -------
        Any
            The evaluated result of the expression.
        """
        if isinstance(node, doc.Call):
            nested_result = self._try_nested_call(node, extra_vars)
            if nested_result is not None:
                return nested_result

        var_values = self.context.get()
        if extra_vars is not None:
            for k, v in extra_vars.items():
                var_values[k] = v
        return ExprEvaluator.eval(node, var_values, self.diag)

    def _apply_bound_dim_values_to_context_frame(self) -> None:
        """Replace symbolic scalars in the current frame with bound concrete values.

        This method is called after bind_dynamic_dims_from_inputs() to concretize
        symbolic dimensions in the current context frame. It iterates through all
        variables in the current frame and replaces SymbolicScalar instances with
        their concrete integer values when available.

        This enables the parser to work with concrete shapes during IR generation
        while maintaining symbolic dimensions in the function signature.
        """
        if not self._bound_dim_values:
            return
        if not self.context.frames:
            return

        current_frame = self.context.frames[-1]
        for var_name in list(current_frame.vars):
            values_stack = self.context.name2value.get(var_name, [])
            if not values_stack:
                continue
            current_value = values_stack[-1]
            if (
                isinstance(current_value, SymbolicScalar)
                and str(current_value) in self._bound_dim_values
            ):
                concrete_value = self._bound_dim_values[str(current_value)]
                self.context.add(var_name, concrete_value, allow_update=True)

    def _normalize_output_annotation(
        self, output_expr: Any, node: doc.AST
    ) -> list[pypto.Tensor]:
        """Validate and normalize return type annotations into a list of tensors.

        Converts various return annotation formats into a normalized list:
        - Single tensor: pypto.Tensor(...) -> [tensor]
        - Tuple/list: (tensor1, tensor2) -> [tensor1, tensor2]

        Parameters
        ----------
        output_expr : Any
            The evaluated return type annotation expression.
        node : doc.AST
            The AST node for error reporting.

        Returns
        -------
        list[pypto.Tensor]
            Normalized list of output tensor definitions.

        Raises
        ------
        ParserError
            If the annotation is not a valid tensor or collection of tensors.
        """
        if isinstance(output_expr, pypto.Tensor):
            return [output_expr]
        if isinstance(output_expr, (list, tuple)):
            tensors: list[pypto.Tensor] = []
            for idx, item in enumerate(output_expr):
                if not isinstance(item, pypto.Tensor):
                    raise ParserError(
                        node,
                        TypeError(
                            f"Return annotation at index {idx} must be a tensor, "
                            f"but got {type(item).__name__}."
                        ),
                    )
                tensors.append(item)
            return tensors

        raise ParserError(
            node,
            TypeError(
                "Return annotation must be a tensor or a list/tuple of tensors, "
                f"but got {type(output_expr).__name__}."
            ),
        )

    def _generic_visit(self, node: doc.AST) -> Any:
        """Generic visit method that visits all child nodes.

        This is called when no specific visit_* method exists for a node type.
        It recursively visits all fields of the node and returns the last non-None result.

        Parameters
        ----------
        node : doc.AST
            The node whose children should be visited.

        Returns
        -------
        res : Any
            The last non-None result from visiting child nodes.
        """
        result = None
        for field in doc.get_cls_fields(node.__class__):
            value = getattr(node, field, None)
            if value is None:
                pass
            elif isinstance(value, (doc.AST, list, tuple)):
                res = self.visit(value)
                if res is not None:
                    result = res
        return result

    def _visit_body(self, node: list[doc.stmt]) -> Any:
        """The general body visiting method.

        Parameters
        ----------
        node : list[doc.stmt]
            The list of statements in body.

        Returns
        -------
        res : Any
            The visiting result.
        """
        for stmt in node:
            self.visit(stmt)
            self._auto_cleanup_after_stmt(stmt)

    def _validate_return_statements(self, node: doc.FunctionDef) -> None:
        """Validate that return statements only appear once at the end of the function.

        Parameters
        ----------
        node : doc.FunctionDef
            The function definition node to validate.

        Raises
        ------
        ParserError
            If there are multiple return statements or a return statement not at the end.
        """

        def find_returns(stmts: list[doc.stmt]) -> list[tuple[int, doc.Return]]:
            """Find all return statements with their positions."""
            returns = []
            for idx, stmt in enumerate(stmts):
                if isinstance(stmt, doc.Return):
                    returns.append((idx, stmt))
                # Check for returns in nested if statements
                elif isinstance(stmt, doc.If):
                    # Check in if body
                    nested_returns = find_returns(stmt.body)
                    if nested_returns:
                        for _, ret in nested_returns:
                            returns.append((idx, ret))
                    # Check in else/elif body
                    if stmt.orelse:
                        nested_returns = find_returns(stmt.orelse)
                        if nested_returns:
                            for _, ret in nested_returns:
                                returns.append((idx, ret))
                # Check for returns in for loops
                elif isinstance(stmt, doc.For):
                    nested_returns = find_returns(stmt.body)
                    if nested_returns:
                        for _, ret in nested_returns:
                            returns.append((idx, ret))
                    if stmt.orelse:
                        nested_returns = find_returns(stmt.orelse)
                        if nested_returns:
                            for _, ret in nested_returns:
                                returns.append((idx, ret))
            return returns

        returns = find_returns(node.body)

        if len(returns) > 1:
            raise ParserError(
                returns[1][1],
                ValueError(
                    "Only one return statement is allowed in a function. "
                    f"Found {len(returns)} return statements."
                ),
            )

        if len(returns) == 1:
            idx, return_node = returns[0]
            # Check if return is at the last position of the function body
            if idx != len(node.body) - 1:
                raise ParserError(
                    return_node,
                    ValueError(
                        "Return statement must be at the last position of the function body. "
                        f"Found return at position {idx}, but function body has {len(node.body)} statements."
                    ),
                )

    def _extract_return_names(self, node: doc.FunctionDef) -> Optional[list[str]]:
        """Extract the variable names being returned from the function.

        Parameters
        ----------
        node : doc.FunctionDef
            The function definition node.

        Returns
        -------
        res : Optional[list[str]]
            List of variable names being returned, or None if no return statement.
        """
        # Find the return statement (should be at the end)
        if not node.body:
            return None

        last_stmt = node.body[-1]
        if not isinstance(last_stmt, doc.Return):
            return None

        if last_stmt.value is None:
            return None

        # Extract variable names from the return value
        return_value = last_stmt.value
        if isinstance(return_value, doc.Name):
            # Single return value: return x
            return [return_value.id]
        elif isinstance(return_value, (doc.Tuple, doc.List)):
            # Multiple return values: return x, y
            names = []
            for elt in return_value.elts:
                if isinstance(elt, doc.Name):
                    names.append(elt.id)
                else:
                    # If return contains expressions (not just names), we can't use this optimization
                    return None
            return names
        else:
            # Return contains an expression, not just variable names
            raise ParserError(
                node,
                ValueError(
                    "Return value must be a variable name or a tuple/list of variable names."
                ),
            )

    def _validate_output_args(
        self, output_args: list[pypto.Tensor], node: doc.FunctionDef
    ) -> None:
        """Validate that output arguments are valid tensors.

        Parameters
        ----------
        output_args : list[pypto.Tensor]
            The output arguments to validate.
        node : doc.FunctionDef
            The function definition node for error reporting.

        Raises
        ------
        ParserError
            If any output argument is invalid.
        """
        for output_arg in output_args:
            # Valid output includes:
            # - pypto.Tensor: -> pypto.Tensor(shape, dtype)
            # - tuple/list of pypto.Tensor: -> tuple/list of pypto.Tensor(shape, dtype)
            # - TODO: type(pypto.Tensor): -> pypto.Tensor

            if output_arg is None:
                raise ParserError(
                    node.returns,
                    ValueError(
                        "Return value must be a tensor with shape and dtype specified."
                    ),
                )

            if output_arg is pypto.Tensor:
                raise ParserError(
                    node.returns,
                    ValueError(
                        "Return value must be a tensor with shape and dtype specified."
                    ),
                )

            if output_arg is not None and not isinstance(output_arg, pypto.Tensor):
                raise ParserError(
                    node.returns,
                    TypeError(
                        f"Return value must be a tensor, but got {type(output_arg)}."
                    ),
                )

    def _mark_dynamic_dimensions(
        self, tensors: list[pypto.Tensor]
    ) -> list[pypto.Tensor]:
        """Mark dynamic dimensions for tensors.

        Dynamic dimensions are those specified with pypto.dynamic() and represented
        as SymbolicScalar objects. This method marks them in the PTO IR.

        Parameters
        ----------
        tensors : list[pypto.Tensor]
            List of tensors to process.

        Returns
        -------
        list[pypto.Tensor]
            List of tensors with dynamic dimensions marked.
        """
        result = []
        for tensor in tensors:
            if isinstance(tensor, pypto.Tensor):
                shape = [
                    -1 if isinstance(dim, pypto.SymbolicScalar) else dim
                    for dim in tensor.shape
                ]
                result.append(pypto.Tensor(shape, tensor.dtype, tensor.name))
            else:
                raise ParserError(
                    tensor,
                    TypeError(
                        f"Tensor must be a pypto.Tensor, but got {type(tensor)}."
                    ),
                )
        return result

    def _add_tensor_args_to_context(self, tensor_args: list[pypto.Tensor]) -> None:
        """Add tensor arguments to the parsing context.

        Parameters
        ----------
        tensor_args : list[pypto.Tensor]
            List of tensor arguments to add to context.
        """
        for arg in tensor_args:
            if isinstance(arg, pypto.Tensor):
                self.context.add(arg.name, arg)

    def _setup_output_var_mapping(
        self, node: doc.FunctionDef, output_args: list[pypto.Tensor]
    ) -> dict[str, pypto.Tensor]:
        """Set up mapping from return variable names to output tensors.

        This method extracts the variable names being returned and maps them to
        the pre-defined output tensors, then adds them to the context.

        Parameters
        ----------
        node : doc.FunctionDef
            The function definition node.
        output_args : list[pypto.Tensor]
            List of output tensors.

        Returns
        -------
        dict[str, pypto.Tensor]
            Mapping from variable names to output tensors.

        Raises
        ------
        ParserError
            If the number of return values doesn't match the number of output tensors.
        """
        return_names = self._extract_return_names(node)
        output_var_mapping = {}

        if return_names is not None:
            if len(return_names) != len(output_args):
                raise ParserError(
                    node.body[-1] if node.body else node,
                    ValueError(
                        f"Return statement has {len(return_names)} values but function signature "
                        f"specifies {len(output_args)} output tensors."
                    ),
                )
            # Map return variable names to pre-defined output tensors
            # and add them to context so they're used directly
            for name, output_tensor in zip(return_names, output_args):
                output_tensor.name = name
                output_var_mapping[name] = output_tensor
                # Add to context so the variable refers to the pre-defined tensor
                self.context.add(name, output_tensor)

        return output_var_mapping

    def _add_metadata_to_context(
        self, func_name: str, output_var_mapping: dict[str, pypto.Tensor]
    ) -> None:
        """Add function metadata to context for use in other visit methods.

        Parameters
        ----------
        func_name : str
            The function name.
        output_var_mapping : dict[str, pypto.Tensor]
            Mapping from variable names to output tensors.
        """
        # Store function name for use in _visit_return
        # TODO: Move to ir builder context once it is implemented.
        self.context.add("__func_name__", func_name)
        # Add output variable mapping to context
        # This tells the parser to use pre-defined output tensors for these variables
        self.context.add("__output_var_mapping__", output_var_mapping)

    def _visit_function_def(self, node: doc.FunctionDef) -> pypto.Function:
        """The general function definition visit method.

        Parameters
        ----------
        node : doc.FunctionDef
            The doc FunctionDef node.

        Note
        ----
        FunctionDef node structure:
            name: str
            args: arguments
            body: list[stmt]
            decorator_list: list[expr]
            returns: Optional[expr]
        """
        # Validate return statements in function body
        self._validate_return_statements(node)

        # Check if function is marked for nested calling (before with block so it can be reused later)
        is_nested = self._is_nested_function(node.decorator_list)

        with self.context.with_frame():
            # Step 1: Extract function signature
            tensor_input_args, output_args = self.get_signature(
                lower_symbolic_dims=True
            )

            # Step 2: Validate output arguments
            self._validate_output_args(output_args, node)

            # Step 3: Set up output variable mapping
            # Note that the naming process should be done before the dynamic dimension marking,
            output_var_mapping = self._setup_output_var_mapping(node, output_args)

            # Step 4: Add arguments to parsing context
            self._add_tensor_args_to_context(tensor_input_args)

            # Step 5: Add metadata to context
            self._add_metadata_to_context(node.name, output_var_mapping)

            # Step 6: Create PTO function and parse body
            if is_nested:
                # For nested functions, we don't create a pypto.Function; body will be inlined on call.
                return None
            else:
                with pypto.function(node.name, *tensor_input_args, *output_args):
                    for _ in pypto.loop(1):
                        self._visit_body(node.body)

        return pypto.functions.get_last_function()

    def _visit_arg(self, node: doc.arg) -> pypto.Tensor:
        """The general arg visiting method.

        Parameters
        ----------
        node : doc.arg
            The doc AST arg node.

        Returns
        -------
        res : pypto.Tensor
            The tensor argument.

        Note
        ----
        arg node structure:
            arg: str
            annotation: expr
        """
        if isinstance(node, (doc.Tuple, doc.List)):
            return [self._visit_arg(arg) for arg in node.elts]
        name = node.arg
        if node.annotation is None:
            raise ParserError(
                node, ValueError("Annotation is required for function arguments.")
            )
        anno = self._visit_expr(node.annotation)
        if isinstance(anno, pypto.Tensor):
            anno.name = name
            return anno
        else:
            raise ParserError(
                node,
                TypeError(
                    f"All function arguments must be pypto.Tensor, but got {type(anno).__name__}."
                ),
            )

    def _parse_arguments_with_specs(
        self, node: doc.arguments
    ) -> tuple[list[pypto.Tensor], list[ParamSpec]]:
        """The general arguments visiting method.

        Parameters
        ----------
        node : doc.arguments
            The doc AST arguments node.

        Returns
        -------
        res : list[pypto.Tensor], list[ParamSpec]]
            List of Tensor arguments, list of ParamSpec arguments
        """
        if node.vararg is not None:
            raise ParserError(
                node,
                NotImplementedError(
                    "Variable-length arguments (*args) are not supported. "
                    "Please use a fixed number of arguments."
                ),
            )
        if len(node.kwonlyargs) > 0:
            raise ParserError(
                node,
                NotImplementedError(
                    "Keyword-only arguments are not supported. "
                    "Please use regular positional or keyword arguments."
                ),
            )
        if len(node.kw_defaults) > 0:
            raise ParserError(
                node,
                NotImplementedError(
                    "Keyword argument defaults are not supported. "
                    "All arguments must be explicitly provided."
                ),
            )
        if node.kwarg is not None:
            raise ParserError(
                node,
                NotImplementedError(
                    "Keyword argument packing (**kwargs) is not supported. "
                    "Please use explicit keyword arguments."
                ),
            )
        if len(node.defaults) > 0:
            raise ParserError(
                node,
                NotImplementedError(
                    "Default argument values are not supported. "
                    "All arguments must be explicitly provided."
                ),
            )
        if len(node.posonlyargs) > 0:
            raise ParserError(
                node,
                NotImplementedError(
                    "Position-only arguments are not supported. "
                    "Please use regular arguments."
                ),
            )

        # Process all arguments (only tensors allowed)
        tensor_args = []
        param_specs: list[ParamSpec] = []

        for arg in node.args:
            result = self._visit_arg(arg)
            if isinstance(result, pypto.Tensor):
                tensor_args.append(result)
                param_specs.append((arg.arg, True, result))
            elif isinstance(result, list):
                # Handle nested tuples/lists if needed
                for item in result:
                    if isinstance(item, pypto.Tensor):
                        tensor_args.append(item)
                        param_specs.append((arg.arg, True, item))

        return tensor_args, param_specs

    def _visit_arguments(self, node: doc.arguments) -> list[pypto.Tensor]:
        """The general arguments visiting method.

        Parameters
        ----------
        node : doc.arguments
            The doc AST arguments node.

        Returns
        -------
        res : tuple[list[pypto.Tensor], list[tuple[str, type]]]
            A tuple of (tensor_args, non_tensor_args) where:
            - tensor_args: list of Tensor arguments
            - non_tensor_args: list of (name, type) tuples for non-tensor arguments
        """
        tensor_args, _ = self._parse_arguments_with_specs(node)
        return tensor_args

    def _try_nested_call(
        self, node: doc.Call, extra_vars: Optional[dict[str, Any]] = None
    ) -> Optional[Any]:
        """Attempt to inline a nested function call marked with @function decorator.

        This method handles inline expansion of functions decorated with
        @pypto.frontend.function. When such a function is called, its body is
        inlined directly into the caller's IR instead of generating a separate
        function call.

        The inlining process:
        1. Identify if the call target is a nested function
        2. Extract the function's AST and environment (closures, globals)
        3. Map call arguments to function parameters
        4. Parse the function body in a new scope with mapped parameters
        5. Return the result value

        Parameters
        ----------
        node : doc.Call
            The function call AST node.
        extra_vars : Optional[dict[str, Any]], optional
            Additional variables to include in the evaluation context.

        Returns
        -------
        Optional[Any]
            The result of the inlined function, or None if inlining is not applicable.

        Raises
        ------
        ParserError
            If the function AST cannot be obtained or parameter mapping fails.
        """
        # Only simple name calls (no attributes/methods) are considered for inlining.
        if not isinstance(node.func, doc.Name):
            return None

        # Collect current context variables and any extra_vars provided by eval_expr.
        func_name = node.func.id
        var_values = self.context.get()
        if extra_vars:
            var_values = {**var_values, **extra_vars}

        if func_name not in var_values:
            return None

        # Resolve the callee function object; if it's a NestedFunctionMarker, unwrap to the original function.
        func_value = var_values[func_name]
        if isinstance(func_value, NestedFunctionMarker):
            func_obj = func_value._original_func
        else:
            func_obj = func_value

        # Merge closure/global variables of the target function to allow resolving
        # free variables used inside the nested function body.
        env_vars = self._collect_function_environment(func_obj)
        if env_vars:
            var_values = {**env_vars, **var_values}

        # Dynamically obtain the FunctionDef AST of the callee; fail fast if unavailable.
        func_def_node = self._get_function_def_from_func(func_obj)
        if func_def_node is None:
            raise ParserError(
                node,
                ValueError(f"Failed to obtain AST for function '{func_name}'."),
            )

        # If callee is a normal function, ensure it is decorated as nested; otherwise, bail out.
        if not isinstance(func_value, NestedFunctionMarker):
            if not self._is_nested_function(func_def_node.decorator_list):
                return None

        # Parse parameters/return annotations to get tensor/non-tensor lists and ordered specs.
        # Seed the temp frame with the callee's env so that annotations depending on globals
        # (e.g., pto, helper constants) resolve correctly.
        with self.context.with_frame():
            for name, value in env_vars.items():
                self.context.add(name, value)

            tensor_input_args, param_specs = self._parse_arguments_with_specs(
                func_def_node.args
            )

            output_args = self._eval_expr(func_def_node.returns, extra_vars=var_values)
            if not isinstance(output_args, (list, tuple)):
                output_args = [output_args]

        # Evaluate call-site arguments; keyword arguments are not supported yet.
        # Use merged env (locals + globals of callee + caller extras) so symbols referenced
        # in the callsite expressions are visible.
        call_args = [self._eval_expr(arg, var_values) for arg in node.args]
        if node.keywords:
            raise ParserError(
                node,
                NotImplementedError(
                    "Keyword arguments in nested function calls are not supported yet."
                ),
            )

        # Validate argument count matches the signature.
        expected_arg_count = len(tensor_input_args)
        if len(call_args) != expected_arg_count:
            raise ParserError(
                node,
                ValueError(
                    f"Function {func_name} expects {expected_arg_count} arguments, "
                    f"but got {len(call_args)}"
                ),
            )

        body_nodes = func_def_node.body
        with self.context.with_frame():
            # Make callee globals/nonlocals available to the inlined body.
            for name, value in env_vars.items():
                self.context.add(name, value)

            # Bind parameters in declared order and validate types.
            for (param_name, is_tensor, annotation), arg_value in zip(
                param_specs, call_args
            ):
                if is_tensor:
                    if not isinstance(arg_value, pypto.Tensor):
                        raise ParserError(
                            node,
                            TypeError(
                                f"Expected tensor argument for {param_name}, "
                                f"got {type(arg_value)}"
                            ),
                        )
                    self.context.add(param_name, arg_value)
                else:
                    if annotation == bool and not isinstance(arg_value, bool):
                        raise ParserError(
                            node,
                            TypeError(
                                f"Expected bool argument for {param_name}, "
                                f"got {type(arg_value)}"
                            ),
                        )
                    if annotation == int and not isinstance(
                        arg_value, (int, pypto.SymbolicScalar)
                    ):
                        raise ParserError(
                            node,
                            TypeError(
                                f"Expected int argument for {param_name}, "
                                f"got {type(arg_value)}"
                            ),
                        )
                    self.context.add(param_name, arg_value)

            # Recreate outputs per return annotation to avoid cross-call interference.
            nested_output_args: list[Any] = []
            for out_arg in output_args:
                if isinstance(out_arg, pypto.Tensor):
                    nested_output_args.append(
                        pypto.Tensor(out_arg.shape, out_arg.dtype, name=out_arg.name)
                    )
                else:
                    nested_output_args.append(out_arg)

            # Preserve outputs in context so visit_return can fill them in-place.
            self.context.add("__func_output_args__", nested_output_args)
            self.context.add("__func_name__", func_name)

            # Inline-execute the callee body.
            old_diag = self.diag
            try:
                try:
                    self.diag = Diagnostics(Source(func_obj))
                except Exception:
                    # Fallback to existing diagnostics if source extraction fails
                    pass

                try:
                    self._visit_body(body_nodes)
                except ParserError as e:
                    if not isinstance(e, RenderedParserError):
                        self.diag.error(e.node, str(e))
                    raise
            except RenderedParserError:
                self.diag = old_diag
                self.diag.info(node, f"In call to '{func_name}'")
                raise
            finally:
                self.diag = old_diag

            # Return aggregation: single tensor returns directly; multiple returns as a list.
            if len(nested_output_args) == 1:
                return nested_output_args[0]
            return nested_output_args

    def _visit_for(self, node: doc.For) -> Any:
        """The general for visiting method.

        Parameters
        ----------
        node : doc.For
            The doc AST for node.

        Returns
        -------
        res : Any
            The visiting result.

        Note
        ----
        For node structure:
            target: expr (loop variable)
            iter: expr (iterator expression, e.g., range(10))
            body: list[stmt] (loop body)
            orelse: list[stmt] (else clause, not supported)
        """
        # Check for unsupported else clause
        if node.orelse:
            raise ParserError(
                node,
                NotImplementedError(
                    "For-else clauses are not supported. "
                    "Consider using a separate if statement after the loop."
                ),
            )

        # Extract the loop variable name
        if not isinstance(node.target, doc.Name):
            raise ParserError(
                node.target,
                TypeError(
                    f"Loop variable must be a simple name, but got {type(node.target).__name__}."
                ),
            )
        loop_var_name = node.target.id

        # Try to evaluate the iterator expression (e.g., range(10))
        # This works even with symbolic values in range bounds because
        # Python's range() is lazily evaluated
        iter_expr = self._eval_expr(node.iter)

        # Support range() calls - extract start, stop, step parameters
        # These parameters can be concrete values or symbolic expressions
        iterator = None
        if isinstance(iter_expr, range):
            # Extract start, stop, step from range object
            start = iter_expr.start
            stop = iter_expr.stop
            step = iter_expr.step
            iterator = pypto.loop(
                start, stop, step, name="Dynamic", idx_name=loop_var_name
            )
        elif isinstance(iter_expr, Iterator):
            iterator = iter_expr
        else:
            raise ParserError(
                node.iter,
                TypeError(
                    f"Loop iterator must be a range object or Iterator, but got {type(iter_expr).__name__}."
                ),
            )

        # Create the loop using pypto.loop, which generates the appropriate IR for iteration.
        # The loop variable is created by the pypto.loop iterator and added to the context
        # so it can be used within the loop body.
        # Create a new frame for the loop body scope
        with self.context.with_frame():
            # The loop variable is yielded by the iterator
            for loop_var in iterator:
                # Add the loop variable to the context
                self.context.add(loop_var_name, loop_var)
                # Visit the loop body
                self._visit_body(node.body)

    def _assign_target(self, target: doc.expr, expr: Any) -> None:
        """Helper method to assign an expression to a target.

        Parameters
        ----------
        target : doc.expr
            The assignment target (Name, Tuple, List, or Subscript).
        expr : Any
            The value to assign.
        """
        if isinstance(target, doc.Name):
            # Simple assignment: a = expr
            # Handle output tensors first to avoid recreating them
            output_var_mapping = self.context.get().get("__output_var_mapping__", {})
            output_tensor = output_var_mapping.get(target.id)
            if output_tensor is not None:
                output_tensor[:] = expr
                return
            # Set the tensor name if expr is a tensor
            if isinstance(expr, pypto.Tensor):
                expr.name = target.id
            self.context.add(target.id, expr)
        elif isinstance(target, (doc.Tuple, doc.List)):
            # Unpacking assignment: a, b = expr
            if not isinstance(expr, (list, tuple)):
                raise ParserError(
                    target,
                    TypeError(f"Cannot unpack non-sequence type {type(expr).__name__}"),
                )
            if len(target.elts) != len(expr):
                raise ParserError(
                    target,
                    ValueError(
                        f"Cannot unpack {len(expr)} values into {len(target.elts)} targets"
                    ),
                )
            for t, e in zip(target.elts, expr):
                self._assign_target(t, e)
        elif isinstance(target, doc.Subscript):
            # Subscript assignment: b[:] = expr or b[0] = expr
            # This handles in-place tensor updates using Python's subscript syntax.
            # Evaluate the value (e.g., b) to get the tensor being assigned to
            tensor = self._eval_expr(target.value)
            # Evaluate the slice (e.g., : or 0) to get the slice/index object
            slice_obj = self._eval_expr(target.slice)
            # Perform the assignment using __setitem__, which translates to
            # the appropriate PTO IR operation for tensor element/slice updates
            tensor[slice_obj] = expr
        else:
            raise ParserError(
                target,
                TypeError(
                    f"Assignment target must be a name, tuple, or subscript, "
                    f"but got {type(target).__name__}."
                ),
            )

    def _visit_assign(self, node: doc.Assign) -> None:
        """The general assign visiting method.

        Parameters
        ----------
        node : doc.Assign
            The doc AST assign node.

        Returns
        -------
        res : None
            The visiting result. None.

        Note
        ----
        Assign node structure:
            targets: list[expr]
            value: expr
        """
        expr = self._visit_expr(node.value)

        for target in node.targets:
            self._assign_target(target, expr)

    def _visit_ann_assign(self, node: doc.AnnAssign) -> Any:
        """The general annotated assign visiting method.

        Parameters
        ----------
        node : doc.Assign
            The doc AST annotated assign node.

        Returns
        -------
        res : Any
            The visiting result.

        Note
        ----
        AnnAssign node structure:
            target: expr
            annotation: expr
            value: Optional[expr]
        """
        # Reuse the assign visiting method to visit the annotated assign node.
        return self._visit_assign(node)

    def _visit_aug_assign(self, node: doc.AugAssign) -> None:
        """The general augmented assign visiting method.

        This method handles compound assignment statements like +=, -=, *=, etc.
        It converts them to equivalent binary operations and assignments.

        Parameters
        ----------
        node : doc.AugAssign
            The doc AST augmented assign node.

        Returns
        -------
        res : None
            The visiting result. None.

        Note
        ----
        AugAssign node structure:
            target: expr
            op: operator (Add, Sub, Mult, Div, etc.)
            value: expr
        """
        # Evaluate the value expression first
        value_expr = self._eval_expr(node.value)
        
        # Handle different target types
        if isinstance(node.target, doc.Name):
            # For Name targets (e.g., out += y), get the value directly from context
            # since node.target has Store context and cannot be evaluated with _eval_expr
            var_values = self.context.get()
            if node.target.id not in var_values:
                raise ParserError(
                    node.target,
                    NameError(f"name '{node.target.id}' is not defined"),
                )
            target_value = var_values[node.target.id]
        elif isinstance(node.target, doc.Subscript):
            # For Subscript targets (e.g., a[i] += y), evaluate the tensor and slice/index
            tensor = self._eval_expr(node.target.value)
            slice_obj = self._eval_expr(node.target.slice)
            
            # Get the current value from the subscript
            target_value = tensor[slice_obj]
        else:
            raise ParserError(
                node.target,
                NotImplementedError(
                    f"Augmented assignment target type {type(node.target).__name__} is not supported."
                ),
            )

        # Perform the binary operation based on the operator type
        if isinstance(node.op, doc.Add):
            result = target_value + value_expr
        elif isinstance(node.op, doc.Sub):
            result = target_value - value_expr
        elif isinstance(node.op, doc.Mult):
            result = target_value * value_expr
        elif isinstance(node.op, doc.Div):
            result = target_value / value_expr
        elif isinstance(node.op, doc.FloorDiv):
            result = target_value // value_expr
        elif isinstance(node.op, doc.Mod):
            result = target_value % value_expr
        elif isinstance(node.op, doc.Pow):
            result = target_value ** value_expr
        elif isinstance(node.op, doc.LShift):
            result = target_value << value_expr
        elif isinstance(node.op, doc.RShift):
            result = target_value >> value_expr
        elif isinstance(node.op, doc.BitAnd):
            result = target_value & value_expr
        elif isinstance(node.op, doc.BitOr):
            result = target_value | value_expr
        elif isinstance(node.op, doc.BitXor):
            result = target_value ^ value_expr
        elif isinstance(node.op, doc.MatMult):
            result = target_value @ value_expr
        else:
            raise ParserError(
                node,
                NotImplementedError(
                    f"Augmented assignment operator {type(node.op).__name__} is not supported."
                ),
            )

        # Assign the result back to the target
        self._assign_target(node.target, result)

    def _visit_expr(self, node: doc.Expr) -> Any:
        """The general expression visiting method.

        Parameters
        ----------
        node : doc.Expr
            The doc AST expression node.

        Returns
        -------
        res : Any
            The visiting result.
        """
        return self._eval_expr(node)

    def _visit_if(self, node: doc.If) -> Any:
        """The general if visiting method.

        Parameters
        ----------
        node : doc.If
            The doc AST if node.

        Returns
        -------
        res : Any
            The visiting result.

        Note
        ----
        If node structure:
            test: expr (condition expression)
            body: list[stmt] (if body)
            orelse: list[stmt] (else/elif body)
        """
        # Evaluate the test condition
        test_expr = self._eval_expr(node.test)

        if isinstance(test_expr, pypto.SymbolicScalar):
            cond = pypto.cond(
                test_expr, file=self.diag.source.source_name, lineno=node.lineno
            )
        elif isinstance(test_expr, bool):
            cond = test_expr
        else:
            raise ParserError(
                node.test,
                TypeError(
                    f"Test condition must be a symbolic scalar or boolean, but got {type(test_expr).__name__}."
                ),
            )

        # Execute the if statement using the condition as a context manager
        if cond:
            # Visit the if body
            self._visit_body(node.body)
        else:
            # Visit the else body (if it exists)
            if node.orelse:
                self._visit_body(node.orelse)

    def _visit_return(self, node: doc.Return) -> Any:
        """The general return visiting method.

        Parameters
        ----------
        node : doc.Return
            The doc AST return node.

        Returns
        -------
        res : Union[None, pypto.Tensor, list[pypto.Tensor]]
            The visiting result: None, a single tensor, or a list of tensors.
        """
        if node.value is None:
            # Case 1: return without any value
            return None

        expr = self._visit_expr(node.value)

        # Case 2: return None (explicit)
        if expr is None:
            return None

        # Get function name and output variable mapping from context
        func_name = self.context.get().get("__func_name__", "")

        # Case 3: return a single tensor
        if isinstance(expr, pypto.Tensor):
            expr.name = f"output_{func_name}"
            result = expr
        # Case 4: return a tuple or list of tensors
        elif isinstance(expr, (list, tuple)):
            result = []
            for idx, elem in enumerate(expr):
                if not isinstance(elem, pypto.Tensor):
                    raise ParserError(
                        node,
                        TypeError(
                            f"Return value at index {idx} must be a tensor, "
                            f"but got {type(elem).__name__}."
                        ),
                    )
                # Name each tensor in the list for better traceability
                if elem.name is None or elem.name == "":
                    elem.name = f"output_{func_name}_{idx}"
                result.append(elem)
        # Case 5: invalid return type
        else:
            raise ParserError(
                node,
                TypeError(
                    f"Return value must be None, a tensor, or a list/tuple of tensors, "
                    f"but got {type(expr).__name__}."
                ),
            )

        # If this return belongs to an inlined nested function, write back
        nested_outputs = self.context.get().get("__func_output_args__")
        if nested_outputs is not None:
            # Write results into the preallocated output tensors so callers reuse them.
            result_list = result if isinstance(result, list) else [result]
            if len(result_list) != len(nested_outputs):
                raise ParserError(
                    node,
                    ValueError(
                        f"Return value count {len(result_list)} does not match expected "
                        f"{len(nested_outputs)}."
                    ),
                )
            for i, tensor in enumerate(result_list):
                if isinstance(nested_outputs[i], pypto.Tensor) and isinstance(
                    tensor, pypto.Tensor
                ):
                    nested_outputs[i][:] = tensor
                else:
                    nested_outputs[i] = tensor
            return nested_outputs if len(nested_outputs) > 1 else nested_outputs[0]

        return result

    def _visit_delete(self, node: doc.Delete) -> None:
        """The general delete visiting method.

        Parameters
        ----------
        node : doc.Delete
            The doc AST delete node.

        Returns
        -------
        res : None
            The visiting result. None.

        Note
        ----
        Delete node structure:
            targets: list[expr]
        """
        for target in node.targets:
            if isinstance(target, doc.Name):
                # Delete a simple variable
                try:
                    self.context.delete(target.id)
                except NameError as e:
                    raise ParserError(target, e) from e
                except ValueError as e:
                    raise ParserError(target, e) from e
            else:
                raise ParserError(
                    target,
                    TypeError(
                        f"Delete target must be a name, "
                        f"but got {type(target).__name__}."
                    ),
                )

    def _auto_cleanup_after_stmt(self, stmt: doc.stmt) -> None:
        """Automatically cleanup variables after statement if enabled.

        Parameters
        ----------
        stmt : doc.stmt
            The statement that was just visited.
        """

        stmt_id = id(stmt)
        if stmt_id in self.delete_after:
            vars_to_delete = self.delete_after[stmt_id]
            self.context.mark_for_deletion(vars_to_delete)
            self.context.cleanup_marked()
